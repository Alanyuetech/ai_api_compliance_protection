# AI Content Filter / AI å†…å®¹è¿‡æ»¤å™¨

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

---

## English

### Overview

AI Content Filter is a lightweight, offline content filtering tool designed to protect applications using AI/LLM APIs from generating inappropriate content. It provides multi-layered filtering including keyword matching, pattern detection, and context analysis.

### Features

- ğŸš€ **Ultra-fast**: Millisecond-level filtering performance
- ğŸ“¦ **Lightweight**: Single executable file ~2-3MB
- ğŸ”’ **Offline**: Works completely offline, no internet required
- ğŸ¯ **Flexible**: Customizable filter rules and modes
- ğŸŒ **Cross-platform**: Works on Windows, Linux, and macOS
- ğŸ”§ **Easy Integration**: Simple command-line interface, works with any programming language

### Project Structure

```
ai_api_compliance_protection/
â”œâ”€â”€ src/                        # Source code (Rust)
â”‚   â”œâ”€â”€ main.rs                # CLI entry point
â”‚   â”œâ”€â”€ filter.rs              # Core filtering engine
â”‚   â””â”€â”€ config.rs              # Configuration management
â”œâ”€â”€ config/                     # Configuration files
â”‚   â””â”€â”€ default_rules.yaml     # Default filter rules (embedded in binary)
â”œâ”€â”€ examples/                   # Integration examples
â”‚   â”œâ”€â”€ python_example.py      # Python integration example
â”‚   â””â”€â”€ nodejs_example.js      # Node.js integration example
â”œâ”€â”€ bin/                        # Compiled binaries (git-ignored)
â”‚   â”œâ”€â”€ ai-filter-linux        # Linux executable
â”‚   â”œâ”€â”€ ai-filter-windows.exe  # Windows executable
â”‚   â””â”€â”€ ai-filter-macos        # macOS executable (build via GitHub Actions)
â”œâ”€â”€ .github/                    # GitHub specific files
â”‚   â””â”€â”€ workflows/             # GitHub Actions workflows
â”‚       â”œâ”€â”€ release.yml        # Multi-platform release workflow
â”‚       â””â”€â”€ build-macos.yml    # macOS build workflow
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ .env                       # Local environment variables (git-ignored)
â”œâ”€â”€ .gitignore                 # Git ignore rules
â”œâ”€â”€ Cargo.toml                 # Rust project configuration
â”œâ”€â”€ Cargo.lock                 # Rust dependencies lock file
â”œâ”€â”€ Dockerfile                 # Docker build configuration
â”œâ”€â”€ Dockerfile.cross           # Cross-platform Docker build
â”œâ”€â”€ filter.example.yaml        # Example custom filter configuration
â”œâ”€â”€ build.sh                   # Simple build script
â”œâ”€â”€ build-all-platforms.sh     # Multi-platform build script
â”œâ”€â”€ build-docker.sh            # Docker-based build script
â”œâ”€â”€ package-release.sh         # Release packaging script
â”œâ”€â”€ upload-release.sh          # GitHub release upload script
â”œâ”€â”€ test.sh                    # Test script
â”œâ”€â”€ LICENSE                    # MIT License
â”œâ”€â”€ README.md                  # This file
â””â”€â”€ INSTALL.md                 # Installation guide
```

### Quick Start

#### Download Pre-compiled Binary

Download the latest release for your platform from the [Releases](https://github.com/Alanyuetech/ai_api_compliance_protection/releases) page:

- Windows: `ai-filter-windows.exe`
- Linux: `ai-filter-linux`
- macOS: `ai-filter-macos`

#### Basic Usage

```bash
# Check text directly
./ai-filter check "Text to check for inappropriate content"

# Check from file
./ai-filter file input.txt

# Pipe input
echo "Some text" | ./ai-filter

# Use custom configuration
./ai-filter check "Text to check" --config custom-rules.yaml

# Different filter modes
./ai-filter check "Text" --mode strict   # Strict filtering
./ai-filter check "Text" --mode moderate # Moderate (default)
./ai-filter check "Text" --mode loose    # Loose filtering
```

#### Integration Examples

**Python:**
```python
import subprocess
import json

def check_content(text):
    result = subprocess.run(
        ['./ai-filter', 'check', text],
        capture_output=True,
        text=True
    )
    return json.loads(result.stdout)

# Use with OpenAI API
response = openai.ChatCompletion.create(...)
check_result = check_content(response.choices[0].message.content)

if check_result['safe']:
    print(response.choices[0].message.content)
else:
    print("Content blocked:", check_result['reason'])
```

**Node.js:**
```javascript
const { execSync } = require('child_process');

function checkContent(text) {
    const result = execSync(`./ai-filter check "${text}"`);
    return JSON.parse(result.toString());
}

// Use with AI API
const aiResponse = await callAIAPI(userInput);
const filterResult = checkContent(aiResponse);

if (filterResult.safe) {
    return aiResponse;
} else {
    return "Content has been filtered for safety.";
}
```

**Shell Script:**
```bash
#!/bin/bash
AI_OUTPUT=$(curl -X POST ... )  # Call AI API
FILTER_RESULT=$(echo "$AI_OUTPUT" | ./ai-filter)

if [ $? -eq 0 ]; then
    echo "$AI_OUTPUT"
else
    echo "Content blocked"
fi
```

### Configuration

#### Environment Variables

For development and release management, create a `.env` file (copy from `.env.example`):

```bash
# Copy the template
cp .env.example .env

# Edit .env and add your GitHub token
nano .env
```

Example `.env` file:
```env
# GitHub Personal Access Token (required for releases)
GITHUB_TOKEN=ghp_your_actual_token_here

# Repository information
GITHUB_OWNER=Alanyuetech
GITHUB_REPO=ai_api_compliance_protection

# Version
VERSION=v1.0.0
```

**Important**: Never commit `.env` file to version control. It's already in `.gitignore`.

#### Filter Configuration

Create a `filter.yaml` file in the same directory as the executable for custom rules:

```yaml
mode: moderate  # strict, moderate, or loose

rules:
  keywords:
    banned:
      - "custom_banned_word"
      - "another_banned_word"
    
    warning:
      - "warning_word"
  
  patterns:
    - pattern: "dangerous.*pattern"
      name: "custom_pattern"
      severity: 0.9
      action: block
  
  whitelist:
    contexts:
      - "educational purpose"
      - "medical discussion"
```

See `filter.example.yaml` for a complete configuration example.

### Build from Source

#### Prerequisites

1. Install Rust: https://rustup.rs/
```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

2. Clone the repository:
```bash
git clone https://github.com/your-repo/ai-content-filter.git
cd ai-content-filter
```

#### Compile

```bash
# Debug build (faster compilation)
cargo build

# Release build (optimized, smaller size)
cargo build --release

# The executable will be in target/release/ai-content-filter
```

#### Cross-compilation

```bash
# Install cross-compilation targets
rustup target add x86_64-pc-windows-gnu
rustup target add x86_64-apple-darwin

# Compile for Windows (from Linux/Mac)
cargo build --release --target x86_64-pc-windows-gnu

# Compile for macOS (from Linux)
cargo build --release --target x86_64-apple-darwin
```

### Output Format

The filter returns JSON with the following structure:

```json
{
  "safe": true,
  "score": 0.95,
  "filtered_content": null,
  "reason": null,
  "matched_rules": []
}
```

- `safe`: Boolean indicating if content is safe
- `score`: Safety score (0.0-1.0, higher is safer)
- `filtered_content`: Filtered version with inappropriate content replaced (if enabled)
- `reason`: Reason for blocking (if blocked)
- `matched_rules`: List of rules that were triggered

### License

MIT License

---

## ä¸­æ–‡

### æ¦‚è¿°

AI å†…å®¹è¿‡æ»¤å™¨æ˜¯ä¸€ä¸ªè½»é‡çº§çš„ç¦»çº¿å†…å®¹è¿‡æ»¤å·¥å…·ï¼Œä¸“é—¨è®¾è®¡ç”¨äºä¿æŠ¤ä½¿ç”¨ AI/LLM API çš„åº”ç”¨ç¨‹åºï¼Œé˜²æ­¢ç”Ÿæˆä¸å½“å†…å®¹ã€‚å®ƒæä¾›å¤šå±‚è¿‡æ»¤ï¼ŒåŒ…æ‹¬å…³é”®è¯åŒ¹é…ã€æ¨¡å¼æ£€æµ‹å’Œä¸Šä¸‹æ–‡åˆ†æã€‚

### ç‰¹æ€§

- ğŸš€ **è¶…å¿«é€Ÿåº¦**ï¼šæ¯«ç§’çº§è¿‡æ»¤æ€§èƒ½
- ğŸ“¦ **è½»é‡çº§**ï¼šå•ä¸ªå¯æ‰§è¡Œæ–‡ä»¶çº¦ 2-3MB
- ğŸ”’ **ç¦»çº¿å·¥ä½œ**ï¼šå®Œå…¨ç¦»çº¿è¿è¡Œï¼Œæ— éœ€ç½‘ç»œ
- ğŸ¯ **çµæ´»é…ç½®**ï¼šå¯è‡ªå®šä¹‰è¿‡æ»¤è§„åˆ™å’Œæ¨¡å¼
- ğŸŒ **è·¨å¹³å°**ï¼šæ”¯æŒ Windowsã€Linux å’Œ macOS
- ğŸ”§ **æ˜“äºé›†æˆ**ï¼šç®€å•çš„å‘½ä»¤è¡Œæ¥å£ï¼Œé€‚ç”¨äºä»»ä½•ç¼–ç¨‹è¯­è¨€

### å¿«é€Ÿå¼€å§‹

#### ä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬

ä» [Releases](https://github.com/Alanyuetech/ai_api_compliance_protection/releases) é¡µé¢ä¸‹è½½é€‚åˆæ‚¨å¹³å°çš„æœ€æ–°ç‰ˆæœ¬ï¼š

- Windows: `ai-filter-windows.exe`
- Linux: `ai-filter-linux`
- macOS: `ai-filter-macos`

#### åŸºæœ¬ä½¿ç”¨

```bash
# ç›´æ¥æ£€æŸ¥æ–‡æœ¬
./ai-filter check "è¦æ£€æŸ¥çš„æ–‡æœ¬å†…å®¹"

# ä»æ–‡ä»¶æ£€æŸ¥
./ai-filter file input.txt

# ç®¡é“è¾“å…¥
echo "ä¸€äº›æ–‡æœ¬" | ./ai-filter

# ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
./ai-filter check "è¦æ£€æŸ¥çš„æ–‡æœ¬" --config custom-rules.yaml

# ä¸åŒçš„è¿‡æ»¤æ¨¡å¼
./ai-filter check "æ–‡æœ¬" --mode strict   # ä¸¥æ ¼è¿‡æ»¤
./ai-filter check "æ–‡æœ¬" --mode moderate # é€‚ä¸­ï¼ˆé»˜è®¤ï¼‰
./ai-filter check "æ–‡æœ¬" --mode loose    # å®½æ¾è¿‡æ»¤
```

#### é›†æˆç¤ºä¾‹

**Python:**
```python
import subprocess
import json

def check_content(text):
    result = subprocess.run(
        ['./ai-filter', 'check', text],
        capture_output=True,
        text=True
    )
    return json.loads(result.stdout)

# ä¸ OpenAI API é…åˆä½¿ç”¨
response = openai.ChatCompletion.create(...)
check_result = check_content(response.choices[0].message.content)

if check_result['safe']:
    print(response.choices[0].message.content)
else:
    print("å†…å®¹å·²è¢«æ‹¦æˆª:", check_result['reason'])
```

**Node.js:**
```javascript
const { execSync } = require('child_process');

function checkContent(text) {
    const result = execSync(`./ai-filter check "${text}"`);
    return JSON.parse(result.toString());
}

// ä¸ AI API é…åˆä½¿ç”¨
const aiResponse = await callAIAPI(userInput);
const filterResult = checkContent(aiResponse);

if (filterResult.safe) {
    return aiResponse;
} else {
    return "å†…å®¹å› å®‰å…¨åŸå› å·²è¢«è¿‡æ»¤ã€‚";
}
```

**Shell è„šæœ¬:**
```bash
#!/bin/bash
AI_OUTPUT=$(curl -X POST ... )  # è°ƒç”¨ AI API
FILTER_RESULT=$(echo "$AI_OUTPUT" | ./ai-filter)

if [ $? -eq 0 ]; then
    echo "$AI_OUTPUT"
else
    echo "å†…å®¹å·²è¢«æ‹¦æˆª"
fi
```

### é…ç½®

åœ¨å¯æ‰§è¡Œæ–‡ä»¶åŒç›®å½•ä¸‹åˆ›å»º `filter.yaml` æ–‡ä»¶æ¥è‡ªå®šä¹‰è§„åˆ™ï¼š

```yaml
mode: moderate  # strictï¼ˆä¸¥æ ¼ï¼‰, moderateï¼ˆé€‚ä¸­ï¼‰, æˆ– looseï¼ˆå®½æ¾ï¼‰

rules:
  keywords:
    banned:
      - "è‡ªå®šä¹‰ç¦ç”¨è¯"
      - "å¦ä¸€ä¸ªç¦ç”¨è¯"
    
    warning:
      - "è­¦å‘Šè¯"
  
  patterns:
    - pattern: "å±é™©.*æ¨¡å¼"
      name: "è‡ªå®šä¹‰æ¨¡å¼"
      severity: 0.9
      action: block
  
  whitelist:
    contexts:
      - "æ•™è‚²ç›®çš„"
      - "åŒ»å­¦è®¨è®º"
```

æŸ¥çœ‹ `filter.example.yaml` è·å–å®Œæ•´é…ç½®ç¤ºä¾‹ã€‚

### ä»æºç æ„å»º

#### å‰ç½®è¦æ±‚

1. å®‰è£… Rust: https://rustup.rs/
```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

2. å…‹éš†ä»“åº“ï¼š
```bash
git clone https://github.com/your-repo/ai-content-filter.git
cd ai-content-filter
```

#### ç¼–è¯‘

```bash
# è°ƒè¯•æ„å»ºï¼ˆç¼–è¯‘æ›´å¿«ï¼‰
cargo build

# å‘å¸ƒæ„å»ºï¼ˆä¼˜åŒ–åï¼Œä½“ç§¯æ›´å°ï¼‰
cargo build --release

# å¯æ‰§è¡Œæ–‡ä»¶å°†åœ¨ target/release/ai-content-filter
```

#### äº¤å‰ç¼–è¯‘

```bash
# å®‰è£…äº¤å‰ç¼–è¯‘ç›®æ ‡
rustup target add x86_64-pc-windows-gnu
rustup target add x86_64-apple-darwin

# ä¸º Windows ç¼–è¯‘ï¼ˆä» Linux/Macï¼‰
cargo build --release --target x86_64-pc-windows-gnu

# ä¸º macOS ç¼–è¯‘ï¼ˆä» Linuxï¼‰
cargo build --release --target x86_64-apple-darwin
```

### è¾“å‡ºæ ¼å¼

è¿‡æ»¤å™¨è¿”å›ä»¥ä¸‹ç»“æ„çš„ JSONï¼š

```json
{
  "safe": true,
  "score": 0.95,
  "filtered_content": null,
  "reason": null,
  "matched_rules": []
}
```

- `safe`: å¸ƒå°”å€¼ï¼Œè¡¨ç¤ºå†…å®¹æ˜¯å¦å®‰å…¨
- `score`: å®‰å…¨åˆ†æ•°ï¼ˆ0.0-1.0ï¼Œè¶Šé«˜è¶Šå®‰å…¨ï¼‰
- `filtered_content`: è¿‡æ»¤åçš„ç‰ˆæœ¬ï¼Œä¸å½“å†…å®¹è¢«æ›¿æ¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
- `reason`: æ‹¦æˆªåŸå› ï¼ˆå¦‚æœè¢«æ‹¦æˆªï¼‰
- `matched_rules`: è§¦å‘çš„è§„åˆ™åˆ—è¡¨

### è®¸å¯è¯

MIT è®¸å¯è¯
